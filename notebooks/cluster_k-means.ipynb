{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09be59f",
   "metadata": {},
   "source": [
    "# Cargar datos #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3faa066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "\n",
    "def preparar_datos_para_clustering(df, columnas_excluir=None):\n",
    "    \"\"\"\n",
    "    Prepara un DataFrame para clustering jer√°rquico:\n",
    "    - Filtra num√©ricas\n",
    "    - Divide por el n√∫mero de jornadas seg√∫n la liga\n",
    "    - Aplica StandardScaler\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: DataFrame original con columna 'Liga'\n",
    "    - columnas_excluir: lista de columnas a mantener fuera (ID, etiquetas)\n",
    "\n",
    "    Retorna:\n",
    "    - df_escalado: array numpy listo para clustering\n",
    "    - df_escalado_df: DataFrame escalado con √≠ndice original\n",
    "    - df_normalizado: DataFrame normalizado por jornadas\n",
    "    \"\"\"\n",
    "    if columnas_excluir is None:\n",
    "        columnas_excluir = []\n",
    "\n",
    "    # Diccionario de jornadas por liga\n",
    "    jornadas_por_liga = {\n",
    "        'Bundesliga': 34,\n",
    "        'Femenino': 30,\n",
    "        'La Liga': 38,\n",
    "        'Ligue 1': 34,  # Nota: Ligue 1 tiene 34 jornadas, no 38\n",
    "        'Premier League': 38,\n",
    "        'Serie A': 38\n",
    "    }\n",
    "\n",
    "    # Separar columnas excluidas\n",
    "    df_excluir = df[columnas_excluir] if columnas_excluir else pd.DataFrame(index=df.index)\n",
    "\n",
    "    # Seleccionar solo num√©ricas no excluidas\n",
    "    df_numeric = df.select_dtypes(include=[np.number]).drop(columns=columnas_excluir, errors='ignore')\n",
    "\n",
    "    # Normalizar por el n√∫mero de jornadas seg√∫n la liga\n",
    "    df_normalizado = df_numeric.astype(float).copy()\n",
    "    \n",
    "    for liga, jornadas in jornadas_por_liga.items():\n",
    "        # Encontrar √≠ndices de equipos de esta liga\n",
    "        indices_liga = df[df['liga'] == liga].index\n",
    "        # Dividir las estad√≠sticas por el n√∫mero de jornadas\n",
    "        df_normalizado.loc[indices_liga] = df_numeric.loc[indices_liga] / jornadas\n",
    "\n",
    "    # Escalar\n",
    "    scaler = StandardScaler()\n",
    "    df_escalado = scaler.fit_transform(df_normalizado)\n",
    "\n",
    "    # Convertimos a DataFrame para conservar estructura\n",
    "    df_escalado_df = pd.DataFrame(df_escalado, index=df.index, columns=df_normalizado.columns)\n",
    "\n",
    "    return df_escalado, df_escalado_df, df_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3068b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path.cwd().parent  # Asume que el notebook est√° en src/ y la ra√≠z es la carpeta padre\n",
    "INPUT_FILE = BASE_DIR / \"output\" / \"Correlation\" / \"filtered_features.csv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "# Preprocesar (excluyendo columnas no num√©ricas o IDs)\n",
    "X, df_ready, X_90 = preparar_datos_para_clustering(df, columnas_excluir=[\"Squad\", \"season\",\"liga\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c9c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de ligas y n√∫mero de clusters √≥ptimo\n",
    "ligas_config = {\n",
    "    'Femenino': {\n",
    "        'Por 90 min': {'clusters': 3},\n",
    "        'Normalizado': {'clusters': 4}\n",
    "    },\n",
    "    'La Liga': {\n",
    "        'Por 90 min': {'clusters': 3},\n",
    "        'Normalizado': {'clusters': 4}\n",
    "    },\n",
    "    'Bundesliga': {\n",
    "        'Por 90 min': {'clusters': 4},\n",
    "        'Normalizado': {'clusters': 3}\n",
    "    },\n",
    "    'Ligue 1': {\n",
    "        'Por 90 min': {'clusters': 3},\n",
    "        'Normalizado': {'clusters': 2}\n",
    "    },\n",
    "    'Serie A': {\n",
    "        'Por 90 min': {'clusters': 5},\n",
    "        'Normalizado': {'clusters': 3}\n",
    "    },\n",
    "    'Premier League': {\n",
    "        'Por 90 min': {'clusters': 3},\n",
    "        'Normalizado': {'clusters': 3}\n",
    "    },\n",
    "    'Global': {\n",
    "        'Por 90 min': {'clusters': 3},\n",
    "        'Normalizado': {'clusters': 3}\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847b987",
   "metadata": {},
   "source": [
    "## Aplicar K-Means\n",
    "Aplicamos K-means a los dos datasets, primero al normalizado y segundo al que almacena los datos por partido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8bfdec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Femenino (Por 90 min) con 3 clusters...\n",
      "Procesando Femenino (Normalizado) con 4 clusters...\n",
      "Procesando La Liga (Por 90 min) con 3 clusters...\n",
      "Procesando La Liga (Normalizado) con 4 clusters...\n",
      "Procesando Bundesliga (Por 90 min) con 4 clusters...\n",
      "Procesando Bundesliga (Normalizado) con 3 clusters...\n",
      "Procesando Ligue 1 (Por 90 min) con 3 clusters...\n",
      "Procesando Ligue 1 (Normalizado) con 2 clusters...\n",
      "Procesando Serie A (Por 90 min) con 5 clusters...\n",
      "Procesando Serie A (Normalizado) con 3 clusters...\n",
      "Procesando Premier League (Por 90 min) con 3 clusters...\n",
      "Procesando Premier League (Normalizado) con 3 clusters...\n",
      "Procesando Global (Por 90 min) con 3 clusters...\n",
      "Procesando Global (Normalizado) con 3 clusters...\n",
      "‚úÖ Exportaci√≥n completada. Todos los CSVs listos para Power BI.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Aseguramos que los √≠ndices coincidan\n",
    "assert (df.index == df_ready.index).all()\n",
    "assert (df.index == X_90.index).all()\n",
    "\n",
    "# Creamos copias de los DataFrames para almacenar clusters\n",
    "df_ready_clusters = df_ready.copy()\n",
    "X_90_clusters = X_90.copy()\n",
    "\n",
    "for liga, config in ligas_config.items():\n",
    "    for tipo, valores in config.items():\n",
    "        n_clusters = valores[\"clusters\"]\n",
    "\n",
    "        print(f\"Procesando {liga} ({tipo}) con {n_clusters} clusters...\")\n",
    "\n",
    "        # Filtrar datos de la liga o usar todos si es Global\n",
    "        if liga == \"Global\":\n",
    "            if tipo == \"Normalizado\":\n",
    "                X_liga = df_ready.copy()\n",
    "            else:  # Por 90 min\n",
    "                X_liga = X_90.copy()\n",
    "            mask = df.index\n",
    "        else:\n",
    "            mask = df[\"liga\"] == liga\n",
    "            if tipo == \"Normalizado\":\n",
    "                X_liga = df_ready.loc[mask]\n",
    "            else:\n",
    "                X_liga = X_90.loc[mask]\n",
    "\n",
    "        # Entrenar KMeans\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        clusters = kmeans.fit_predict(X_liga)\n",
    "\n",
    "        # Crear nombre de columna\n",
    "        col_name = f\"Cluster_{tipo.replace(' ', '')}_{liga.replace(' ', '_')}\"\n",
    "\n",
    "        # Guardar resultados en los tres DataFrames\n",
    "        df.loc[mask, col_name] = clusters + 1\n",
    "        if tipo == \"Normalizado\":\n",
    "            df_ready_clusters.loc[mask, col_name] = clusters + 1\n",
    "        else:\n",
    "            X_90_clusters.loc[mask, col_name] = clusters + 1\n",
    "\n",
    "# A√±adir columnas de contexto a df_ready_clusters y X_90_clusters\n",
    "for df_cluster in [df_ready_clusters, X_90_clusters]:\n",
    "    df_cluster[\"Squad\"] = df[\"Squad\"]\n",
    "    df_cluster[\"season\"] = df[\"season\"]\n",
    "    df_cluster[\"liga\"] = df[\"liga\"]\n",
    "\n",
    "# Ahora s√≠ podemos exportar\n",
    "cols_clave = [\"Squad\", \"season\", \"liga\"]\n",
    "\n",
    "df_ready_export = df_ready_clusters[cols_clave + [c for c in df_ready_clusters.columns if c.startswith(\"Cluster_\")]]\n",
    "X_90_export = X_90_clusters[cols_clave + [c for c in X_90_clusters.columns if c.startswith(\"Cluster_\")]]\n",
    "df_export = df[cols_clave + [c for c in df.columns if c.startswith(\"Cluster_\")]]\n",
    "\n",
    "# Guardar CSVs\n",
    "df_export.to_csv(\"resultados_kmeans_clusters.csv\", index=False)\n",
    "df_ready_export.to_csv(\"resultados_kmeans_clusters_normalizado.csv\", index=False)\n",
    "X_90_export.to_csv(\"resultados_kmeans_clusters_X90.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Exportaci√≥n completada. Todos los CSVs listos para Power BI.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciendo La Liga usando Femenino (Por 90 min) con 3 clusters...\n",
      "Prediciendo La Liga usando Femenino (Normalizado) con 4 clusters...\n",
      "Prediciendo La Liga usando Bundesliga (Por 90 min) con 4 clusters...\n",
      "Prediciendo La Liga usando Bundesliga (Normalizado) con 3 clusters...\n",
      "Prediciendo La Liga usando Ligue 1 (Por 90 min) con 3 clusters...\n",
      "Prediciendo La Liga usando Ligue 1 (Normalizado) con 2 clusters...\n",
      "Prediciendo La Liga usando Serie A (Por 90 min) con 5 clusters...\n",
      "Prediciendo La Liga usando Serie A (Normalizado) con 3 clusters...\n",
      "Prediciendo La Liga usando Premier League (Por 90 min) con 3 clusters...\n",
      "Prediciendo La Liga usando Premier League (Normalizado) con 3 clusters...\n",
      "Prediciendo La Liga usando Global (Por 90 min) con 3 clusters...\n",
      "‚ö†Ô∏è No hay datos para Global (Por 90 min), saltando...\n",
      "Prediciendo La Liga usando Global (Normalizado) con 3 clusters...\n",
      "‚ö†Ô∏è No hay datos para Global (Normalizado), saltando...\n",
      "\n",
      "‚úÖ Predicciones completadas y guardadas en 'predicciones_vs_laliga.csv'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import pandas as pd\n",
    "\n",
    "resultados = []\n",
    "\n",
    "liga_destino = \"La Liga\"\n",
    "\n",
    "for liga_origen, config in ligas_config.items():\n",
    "    if liga_origen == liga_destino:\n",
    "        continue  # no tiene sentido comparar la liga consigo misma\n",
    "\n",
    "    for tipo, valores in config.items():\n",
    "        n_clusters = valores[\"clusters\"]\n",
    "\n",
    "        print(f\"Prediciendo {liga_destino} usando {liga_origen} ({tipo}) con {n_clusters} clusters...\")\n",
    "\n",
    "        # Filtrar origen y destino\n",
    "        if tipo == \"Normalizado\":\n",
    "            X_origen = df_ready[df[\"liga\"] == liga_origen]\n",
    "            X_destino = df_ready[df[\"liga\"] == liga_destino]\n",
    "        else:  # Por 90 min\n",
    "            X_origen = X_90[df[\"liga\"] == liga_origen]\n",
    "            X_destino = X_90[df[\"liga\"] == liga_destino]\n",
    "\n",
    "        # Comprobar que hay datos\n",
    "        if X_origen.empty:\n",
    "            print(f\"‚ö†Ô∏è No hay datos para {liga_origen} ({tipo}), saltando...\")\n",
    "            continue\n",
    "\n",
    "        # Etiquetas reales de origen\n",
    "        y_origen = df.loc[X_origen.index, f\"Cluster_{tipo.replace(' ', '')}_{liga_origen.replace(' ', '_')}\"]\n",
    "\n",
    "        # Entrenar en destino (La Liga)\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        kmeans.fit(X_destino)\n",
    "\n",
    "        # Predecir para equipos de origen en el modelo entrenado en La Liga\n",
    "        y_pred = kmeans.predict(X_origen) + 1\n",
    "\n",
    "        # Calcular ARI\n",
    "        ari = adjusted_rand_score(y_origen, y_pred)\n",
    "\n",
    "        # ---- C√°lculo de separaciones usando groupby ----\n",
    "        df_temp = pd.DataFrame({\n",
    "            \"cluster_origen\": y_origen,\n",
    "            \"cluster_predicho\": y_pred\n",
    "        })\n",
    "\n",
    "        separaciones = {}\n",
    "        total_separados = 0\n",
    "\n",
    "        # Para cada cluster de origen, identificar el cluster predicho m√°s frecuente\n",
    "        for cluster_real, grupo in df_temp.groupby(\"cluster_origen\"):\n",
    "            cluster_ref = grupo[\"cluster_predicho\"].mode()[0]  # cluster m√°s frecuente\n",
    "            separados = (grupo[\"cluster_predicho\"] != cluster_ref).sum()\n",
    "            separaciones[int(cluster_real)] = int(separados)\n",
    "            total_separados += separados\n",
    "\n",
    "        resultados.append({\n",
    "            \"Liga_origen\": liga_origen,\n",
    "            \"Tipo\": tipo,\n",
    "            \"Clusters\": n_clusters,\n",
    "            \"ARI_vs_LaLiga\": ari,\n",
    "            \"Separaciones_por_cluster\": separaciones,\n",
    "            \"Total_separados\": int(total_separados),\n",
    "            \"Equipos_origen\": len(X_origen)\n",
    "        })\n",
    "\n",
    "# Guardar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados.to_csv(\"predicciones_vs_laliga.csv\", index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Predicciones completadas y guardadas en 'predicciones_vs_laliga.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81d97016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Resumen de predicciones vs La Liga:\n",
      "\n",
      "Mejor ARI: Bundesliga (Normalizado) -> ARI = 0.947, Separados = 0/18\n",
      "Peor ARI: Bundesliga (Por 90 min) -> ARI = 0.359, Separados = 5/18\n",
      "Mayor proporci√≥n de separados: Bundesliga (Por 90 min) -> 27.8% de equipos separados\n",
      "Menor proporci√≥n de separados: Bundesliga (Normalizado) -> 0.0% de equipos separados\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar resultados\n",
    "df_resultados = pd.read_csv(\"predicciones_vs_laliga.csv\")\n",
    "\n",
    "# A√±adir columna de proporci√≥n de separados\n",
    "df_resultados[\"Proporcion_separados\"] = df_resultados[\"Total_separados\"] / df_resultados[\"Equipos_origen\"]\n",
    "\n",
    "# Liga/tipo con mejor ARI\n",
    "mejor_ari = df_resultados.loc[df_resultados[\"ARI_vs_LaLiga\"].idxmax()]\n",
    "\n",
    "# Liga/tipo con peor ARI\n",
    "peor_ari = df_resultados.loc[df_resultados[\"ARI_vs_LaLiga\"].idxmin()]\n",
    "\n",
    "# Liga/tipo con mayor proporci√≥n de separados\n",
    "mayor_sep = df_resultados.loc[df_resultados[\"Proporcion_separados\"].idxmax()]\n",
    "\n",
    "# Liga/tipo con menor proporci√≥n de separados\n",
    "menor_sep = df_resultados.loc[df_resultados[\"Proporcion_separados\"].idxmin()]\n",
    "\n",
    "print(\"üìä Resumen de predicciones vs La Liga:\\n\")\n",
    "\n",
    "print(f\"Mejor ARI: {mejor_ari['Liga_origen']} ({mejor_ari['Tipo']}) -> ARI = {mejor_ari['ARI_vs_LaLiga']:.3f}, \"\n",
    "      f\"Separados = {mejor_ari['Total_separados']}/{mejor_ari['Equipos_origen']}\")\n",
    "\n",
    "print(f\"Peor ARI: {peor_ari['Liga_origen']} ({peor_ari['Tipo']}) -> ARI = {peor_ari['ARI_vs_LaLiga']:.3f}, \"\n",
    "      f\"Separados = {peor_ari['Total_separados']}/{peor_ari['Equipos_origen']}\")\n",
    "\n",
    "print(f\"Mayor proporci√≥n de separados: {mayor_sep['Liga_origen']} ({mayor_sep['Tipo']}) -> \"\n",
    "      f\"{mayor_sep['Proporcion_separados']*100:.1f}% de equipos separados\")\n",
    "\n",
    "print(f\"Menor proporci√≥n de separados: {menor_sep['Liga_origen']} ({menor_sep['Tipo']}) -> \"\n",
    "      f\"{menor_sep['Proporcion_separados']*100:.1f}% de equipos separados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13f05a",
   "metadata": {},
   "source": [
    "## A√±adimos variables PCA para poder graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4de7730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PCA aplicado y columnas a√±adidas para Normalizado\n",
      "‚úÖ PCA aplicado y columnas a√±adidas para Por90Min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Diccionario para recorrer los dos DataFrames\n",
    "dfs = {\n",
    "    \"Normalizado\": df_ready_clusters,\n",
    "    \"Por90Min\": X_90_clusters\n",
    "}\n",
    "\n",
    "for tipo, df_tipo in dfs.items():\n",
    "    # Columnas num√©ricas para PCA (excluyendo ID y clusters)\n",
    "    cols_excluir = [\"Squad\", \"season\", \"liga\"] + [c for c in df_tipo.columns if c.startswith(\"Cluster_\")]\n",
    "    X_pca_input = df_tipo.drop(columns=cols_excluir, errors=\"ignore\")\n",
    "\n",
    "    if X_pca_input.empty:\n",
    "        print(f\"‚ö†Ô∏è No hay columnas para PCA en {tipo}\")\n",
    "        continue\n",
    "\n",
    "    # Imputar NaN con la media\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_clean = imputer.fit_transform(X_pca_input)\n",
    "\n",
    "    # PCA 2D\n",
    "    pca2 = PCA(n_components=2, random_state=42)\n",
    "    X_pca2 = pca2.fit_transform(X_clean)\n",
    "    df_tipo[\"PCA2D_1\"] = X_pca2[:, 0]\n",
    "    df_tipo[\"PCA2D_2\"] = X_pca2[:, 1]\n",
    "\n",
    "    # PCA 3D\n",
    "    pca3 = PCA(n_components=3, random_state=42)\n",
    "    X_pca3 = pca3.fit_transform(X_clean)\n",
    "    df_tipo[\"PCA3D_1\"] = X_pca3[:, 0]\n",
    "    df_tipo[\"PCA3D_2\"] = X_pca3[:, 1]\n",
    "    df_tipo[\"PCA3D_3\"] = X_pca3[:, 2]\n",
    "\n",
    "    # PCA Radar (6D)\n",
    "    pca6 = PCA(n_components=6, random_state=42)\n",
    "    X_pca6 = pca6.fit_transform(X_clean)\n",
    "    for i in range(6):\n",
    "        df_tipo[f\"PCARadar_{i+1}\"] = X_pca6[:, i]\n",
    "\n",
    "    print(f\"‚úÖ PCA aplicado y columnas a√±adidas para {tipo}\")\n",
    "\n",
    "# Exportar los DataFrames con clusters y PCA\n",
    "df_ready_clusters.to_csv(\"df_ready_clusters_con_PCA.csv\", index=False)\n",
    "X_90_clusters.to_csv(\"X90_clusters_con_PCA.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3537be",
   "metadata": {},
   "source": [
    "## Definir las variables m√°s importantes\n",
    "De esta forma sacamos las 6 variables m√°s relevantes para poder sacar un buen gr√°fico de radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19d2e3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Seleccionando variables m√°s importantes para Femenino (Por 90 min)...\n",
      "\n",
      "üîé Seleccionando variables m√°s importantes para Femenino (Normalizado)...\n",
      "\n",
      "üîé Seleccionando variables m√°s importantes para Bundesliga (Por 90 min)...\n",
      "\n",
      "üîé Seleccionando variables m√°s importantes para Bundesliga (Normalizado)...\n",
      "\n",
      "üîé Seleccionando variables m√°s importantes para Ligue 1 (Por 90 min)...\n",
      "\n",
      "üîé Seleccionando variables m√°s importantes para Ligue 1 (Normalizado)...\n",
      "\n",
      "üîé Seleccionando variables m√°s importantes para Serie A (Por 90 min)...\n",
      "\n",
      "üîé Seleccionando variables m√°s importantes para Serie A (Normalizado)...\n",
      "\n",
      "üîé Seleccionando variables m√°s importantes para Premier League (Por 90 min)...\n",
      "\n",
      "üîé Seleccionando variables m√°s importantes para Premier League (Normalizado)...\n",
      "\n",
      "üîé Seleccionando variables m√°s importantes para Global (Por 90 min)...\n",
      "‚ö†Ô∏è No hay datos para Global (Por 90 min), saltando...\n",
      "\n",
      "üîé Seleccionando variables m√°s importantes para Global (Normalizado)...\n",
      "‚ö†Ô∏è No hay datos para Global (Normalizado), saltando...\n",
      "\n",
      "‚úÖ Selecci√≥n completada:\n",
      "- Guardado top6 por liga en 'top6_variables_por_liga.csv'\n",
      "- Guardado top6 global en 'top6_variables_global.csv'\n",
      "\n",
      "üèÜ Top6 variables globales:\n",
      "                             Variable  Importancia_media\n",
      "0  Unnamed: 24_level_0 CrsPA_against           0.071333\n",
      "1               Team Success PPM_for           0.058476\n",
      "2         Unnamed: 3_level_0 Att_for           0.051814\n",
      "3            Touches Def Pen_against           0.051493\n",
      "4           Corner Kicks Out_against           0.051333\n",
      "5                  Blocks Sh_against           0.048995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Guardaremos aqu√≠ las variables top por liga/tipo\n",
    "top_vars_resultados = []\n",
    "\n",
    "liga_destino = \"La Liga\"\n",
    "\n",
    "for liga_origen, config in ligas_config.items():\n",
    "    if liga_origen == liga_destino:\n",
    "        continue  # no comparar contra s√≠ misma\n",
    "\n",
    "    for tipo, valores in config.items():\n",
    "        n_clusters = valores[\"clusters\"]\n",
    "\n",
    "        print(f\"\\nüîé Seleccionando variables m√°s importantes para {liga_origen} ({tipo})...\")\n",
    "\n",
    "        # Filtrar origen usando df[\"liga\"] como m√°scara\n",
    "        if tipo == \"Normalizado\":\n",
    "            mask = df[\"liga\"] == liga_origen\n",
    "            X_origen = df_ready.loc[mask].drop(columns=[\"liga\"], errors=\"ignore\")\n",
    "        else:  # Por 90 min\n",
    "            mask = df[\"liga\"] == liga_origen\n",
    "            X_origen = X_90.loc[mask].drop(columns=[\"liga\"], errors=\"ignore\")\n",
    "\n",
    "        if X_origen.empty:\n",
    "            print(f\"‚ö†Ô∏è No hay datos para {liga_origen} ({tipo}), saltando...\")\n",
    "            continue\n",
    "\n",
    "        # Etiquetas reales de origen\n",
    "        cluster_col = f\"Cluster_{tipo.replace(' ', '')}_{liga_origen.replace(' ', '_')}\"\n",
    "        y_origen = df.loc[X_origen.index, cluster_col]\n",
    "\n",
    "        # Entrenar RandomForest para ver importancia de variables\n",
    "        rf = RandomForestClassifier(random_state=42, n_estimators=300)\n",
    "        rf.fit(X_origen, y_origen)\n",
    "\n",
    "        importancias = pd.Series(rf.feature_importances_, index=X_origen.columns)\n",
    "        top6 = importancias.sort_values(ascending=False).head(6)\n",
    "\n",
    "        # Guardar resultados individuales\n",
    "        for var, imp in top6.items():\n",
    "            top_vars_resultados.append({\n",
    "                \"Liga_origen\": liga_origen,\n",
    "                \"Tipo\": tipo,\n",
    "                \"Variable\": var,\n",
    "                \"Importancia\": imp\n",
    "            })\n",
    "\n",
    "# ---- Guardar top6 por liga/tipo ----\n",
    "df_top_vars = pd.DataFrame(top_vars_resultados)\n",
    "df_top_vars.to_csv(\"top6_variables_por_liga.csv\", index=False)\n",
    "\n",
    "# ---- Calcular top6 globales ----\n",
    "# Agrupamos todas las importancias de todas las ligas\n",
    "df_global = df_top_vars.groupby(\"Variable\")[\"Importancia\"].mean().sort_values(ascending=False)\n",
    "\n",
    "# Seleccionamos las 6 m√°s importantes en general\n",
    "top6_global = df_global.head(6).reset_index()\n",
    "top6_global.columns = [\"Variable\", \"Importancia_media\"]\n",
    "\n",
    "# Guardar en otro CSV\n",
    "top6_global.to_csv(\"top6_variables_global.csv\", index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Selecci√≥n completada:\")\n",
    "print(\"- Guardado top6 por liga en 'top6_variables_por_liga.csv'\")\n",
    "print(\"- Guardado top6 global en 'top6_variables_global.csv'\")\n",
    "print(\"\\nüèÜ Top6 variables globales:\\n\", top6_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd00c00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Componente PC1:\n",
      "Unnamed: 22_level_0 1/3_for    0.179687\n",
      "SCA SCA_for                    0.168475\n",
      "Team Success PPM_for           0.167466\n",
      "GCA GCA_for                    0.167391\n",
      "Unnamed: 3_level_0 Att_for     0.162141\n",
      "Name: PC1, dtype: float64\n",
      "\n",
      "Componente PC2:\n",
      "Long Att_for             0.184150\n",
      "Performance Recov_for    0.178647\n",
      "Pass Types Sw_against    0.174213\n",
      "Touches Def Pen_for      0.171977\n",
      "Pass Types Dead_for      0.170235\n",
      "Name: PC2, dtype: float64\n",
      "\n",
      "Componente PC3:\n",
      "Starts Mn/Start_for      0.245374\n",
      "Tackles TklW_for         0.233870\n",
      "Standard Dist_for        0.216071\n",
      "Standard Dist_against    0.214579\n",
      "Carries Dis_against      0.214130\n",
      "Name: PC3, dtype: float64\n",
      "\n",
      "Componente PC4:\n",
      "Challenges Lost_against    0.238222\n",
      "Touches Def 3rd_against    0.194594\n",
      "Subs Subs_for              0.180375\n",
      "Take-Ons Att_for           0.175425\n",
      "Carries Mis_against        0.174881\n",
      "Name: PC4, dtype: float64\n",
      "\n",
      "Componente PC5:\n",
      "Take-Ons Att_against               0.254500\n",
      "Pass Types TB_against              0.237096\n",
      "Challenges Tkl_for                 0.227355\n",
      "Unnamed: 17_level_0 Clr_against    0.212705\n",
      "Tackles Mid 3rd_for                0.209541\n",
      "Name: PC5, dtype: float64\n",
      "\n",
      "Componente PC6:\n",
      "Standard G/Sh_against       0.304549\n",
      "GCA GCA_against             0.256820\n",
      "Expected G-xG_against       0.243671\n",
      "Expected npxG/Sh_against    0.222069\n",
      "Performance Off_against     0.185430\n",
      "Name: PC6, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Columnas originales: solo num√©ricas, sin clusters ni PCA\n",
    "cols_excluir = [\"Squad\", \"season\", \"liga\"] + [c for c in df_ready_clusters.columns if c.startswith(\"Cluster_\") or c.startswith(\"PCA\")]\n",
    "X_clean_df = df_ready_clusters.drop(columns=cols_excluir, errors=\"ignore\")\n",
    "\n",
    "# Imputar NaN\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_clean = imputer.fit_transform(X_clean_df)\n",
    "\n",
    "# PCA 6D\n",
    "from sklearn.decomposition import PCA\n",
    "pca6 = PCA(n_components=6, random_state=42)\n",
    "pca6.fit(X_clean)\n",
    "\n",
    "# Loadings: contribuciones de las variables originales\n",
    "loadings = pd.DataFrame(pca6.components_.T, \n",
    "                        columns=[f\"PC{i+1}\" for i in range(6)], \n",
    "                        index=X_clean_df.columns)\n",
    "\n",
    "# Ver las 5 variables que m√°s aportan a cada componente\n",
    "for i in range(6):\n",
    "    print(f\"\\nComponente PC{i+1}:\")\n",
    "    print(loadings[f\"PC{i+1}\"].abs().sort_values(ascending=False).head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a337b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_radar = {\n",
    "    \"PC1\": \"Creaci√≥n Ofensiva / Eficacia\",\n",
    "    \"PC2\": \"Transiciones / Recuperaci√≥n\",\n",
    "    \"PC3\": \"Defensa / Contribuci√≥n Individual\",\n",
    "    \"PC4\": \"Distribuci√≥n / Posesi√≥n\",\n",
    "    \"PC5\": \"Finalizaci√≥n / Remate\",\n",
    "    \"PC6\": \"Defensa / Prevenci√≥n de goles\"\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
